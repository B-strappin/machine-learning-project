---
title: "Practical Machine Learning Final Project"
author: "Seth Sanford"
date: "August 24, 2014"
output: html_document
---

#Summary
This project requires you to dive into a large dataset of exercise enthusiasts and create a model based on this data in order to determine what type of exercise an individual is doing based on the data that is being created by their human activity monitor.

I created my model with the randomForest() function in order to have a more robust solution compared to a linear regression approach. My resulting methodology resulted in a robust model with an estimated error rate of 0.31% using 500 trees with 7 variables tried at each split.

However, the error rates are not the same for all activities. You can see a histogram showing this below.


##Download the data and libraries
In order to work with the data, we needed to make sure the correct values in each column that were NA's were actually read as NA's and that none of the columns that were not supposed to be factors were not read as such. 

```{r}
library(data.table)
traindata <- read.csv("pml-training.csv", stringsAsFactors=FALSE, na.strings=c("NA",""))
testdata <- read.csv("pml-testing.csv", stringsAsFactors=FALSE, na.strings=c("NA",""))
```

##Process the data
Make the classe variable in training dataset factor

```{r}
traindata$classe <- as.factor(traindata$classe)
```

Get rid of columns with all NAs

```{r}
traindata <- traindata[,complete.cases(t(traindata))]
testdata <- testdata[,complete.cases(t(testdata))]
```

Get rid of columns that are not measurements

```{r}
traindata <- traindata[,-c(1:7)]
testdata <- testdata[,-c(1:7)]
```

Remove rows in train set with NAs if any

```{r}
traindata <- traindata[complete.cases(traindata),]
```

##Fit a model to the processed training data
Create a model with randomForest() for a better than linear regression model. I was unable to use the train function with the random forest methodology because it simply took way too long to process.

```{r, warning=FALSE}
library("randomForest")
modFit <- randomForest(classe ~ ., data=traindata)
```

If we explore the basic confusion matrix of our model:
```{r}
modFit
```

We can see that based on our training sample, we have a very well correlated and robust model with an error rate of 0.31% using 500 trees with 7 variables tried at each split.

Show differences in error rate for consideration
```{r, fig.height=6, fig.width=8}
conf <- modFit$confusion
confdata <- data.frame(row.names(conf)[1:5],conf[,"class.error"])
names(confdata) <- c("Activity","Error.Rate")
barplot(confdata$Error.Rate, main="Error Rates", xlab="Activity", ylab="Error Rate", 
        names.arg=confdata$Activity,border="blue")
```

Create character vector of predictions
```{r}
predictions <- predict(modFit,testdata)
predictions <- as.character(predictions)
```

Write out the character vector to individual files for submission
```{r}
pml_write_files = function(x){
    n = length(x)
    for(i in 1:n){
        filename = paste0("answers/problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}

pml_write_files(predictions)
```
